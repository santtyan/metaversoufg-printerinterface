"""
Sistema de Logging Cient√≠fico para Documenta√ß√£o Qualis A1
Sistema automatizado para captura de dados experimentais com rigor cient√≠fico

PROP√ìSITO: Registra AUTOMATICAMENTE todas as m√©tricas necess√°rias para
publica√ß√£o cient√≠fica enquanto voc√™ executa os experimentos.

QUANDO USAR: Integrado com seus scripts de an√°lise. Roda em background
capturando m√©tricas, tempos de resposta, taxas de sucesso, etc.

BENEF√çCIO: Ao final, voc√™ tem dataset completo pronto para an√°lise estat√≠stica
e figuras prontas para publica√ß√£o A1.
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import statistics
import scipy.stats as stats
from contextlib import contextmanager
import hashlib

@dataclass
class ExperimentalConditions:
    """
    Condi√ß√µes experimentais documentadas com rigor
    
    PROP√ìSITO: Armazena TODAS as condi√ß√µes do experimento para
    reprodutibilidade. Cr√≠tico para valida√ß√£o cient√≠fica.
    """
    session_id: str  # ID √∫nico da sess√£o
    start_time: datetime
    end_time: Optional[datetime] = None
    printer_firmware_version: str = "Unknown"
    network_configuration: Dict[str, str] = None
    ambient_temperature: Optional[float] = None
    operator: str = "Pesquisador"  # Seu nome
    experimental_phase: str = "Discovery"
    
    def __post_init__(self):
        if self.network_configuration is None:
            self.network_configuration = {}

@dataclass
class CommandExecution:
    """
    Registro individual de execu√ß√£o de comando
    
    PROP√ìSITO: Captura CADA execu√ß√£o de comando com m√©tricas precisas.
    Base para an√°lise estat√≠stica posterior.
    """
    timestamp: datetime
    session_id: str
    command_id: str
    command_payload: Dict[str, Any]
    response_received: bool
    response_time_ms: Optional[float]  # Tempo de resposta em milissegundos
    response_payload: Optional[Dict[str, Any]]
    success_indicators: List[str]  # Lista de indicadores de sucesso
    failure_indicators: List[str]  # Lista de indicadores de falha
    network_conditions: Dict[str, Any]
    retry_attempt: int = 0  # N√∫mero da tentativa (0 = primeira)
    
    @property
    def is_successful(self) -> bool:
        """Determina se execu√ß√£o foi bem-sucedida"""
        return self.response_received and len(self.success_indicators) > 0

@dataclass
class StatisticalSummary:
    """
    Sum√°rio estat√≠stico rigoroso para publica√ß√£o
    
    INCLUI: Todas as m√©tricas exigidas por journals A1:
    - M√©dia, mediana, desvio padr√£o
    - Percentis (25, 75, 95)
    - Intervalos de confian√ßa 95%
    """
    metric_name: str
    sample_size: int
    mean: float
    median: float
    std_dev: float
    min_value: float
    max_value: float
    percentile_25: float
    percentile_75: float
    percentile_95: float
    confidence_interval_95: tuple
    
    @classmethod
    def from_data(cls, metric_name: str, data: List[float]) -> 'StatisticalSummary':
        """
        Cria sum√°rio estat√≠stico a partir de dados brutos
        
        CALCULA: Todas as m√©tricas estat√≠sticas automaticamente
        """
        if not data:
            return cls(metric_name, 0, 0, 0, 0, 0, 0, 0, 0, 0, (0, 0))
        
        array = np.array(data)
        
        # Calcula intervalo de confian√ßa 95% usando distribui√ß√£o t
        confidence_interval = stats.t.interval(
            0.95, len(data)-1, loc=np.mean(data), scale=stats.sem(data)
        )
        
        return cls(
            metric_name=metric_name,
            sample_size=len(data),
            mean=float(np.mean(array)),
            median=float(np.median(array)),
            std_dev=float(np.std(array)),
            min_value=float(np.min(array)),
            max_value=float(np.max(array)),
            percentile_25=float(np.percentile(array, 25)),
            percentile_75=float(np.percentile(array, 75)),
            percentile_95=float(np.percentile(array, 95)),
            confidence_interval_95=confidence_interval
        )

class ScientificLogger:
    """
    Logger cient√≠fico para documenta√ß√£o rigorosa de experimentos
    
    USO T√çPICO:
```python
    logger = ScientificLogger("Experimento_K1Max")
    
    with logger.experimental_session("Descoberta_API") as session_id:
        # Execute seus experimentos aqui
        logger.log_command_execution(
            session_id=session_id,
            command_id="get_status",
            command_payload={"cmd": "get_status"},
            response_time_ms=15.3,
            success_indicators=["status"]
        )
    
    # Ao final, gera relat√≥rios automaticamente
    logger.generate_statistical_analysis()
    logger.generate_publication_figures()

"""

def __init__(self, experiment_name: str, data_directory: str = "experimental_data"):
    """
    Inicializa logger cient√≠fico
    
    PAR√ÇMETROS:
    - experiment_name: Nome do experimento (usado nos arquivos)
    - data_directory: Pasta onde dados ser√£o salvos
    """
    self.experiment_name = experiment_name
    self.data_directory = Path(data_directory)
    self.data_directory.mkdir(exist_ok=True)
    
    # Estruturas de dados experimentais
    self.experimental_sessions: Dict[str, ExperimentalConditions] = {}
    self.command_executions: List[CommandExecution] = []
    self.performance_metrics: Dict[str, List[float]] = {}
    
    # Configura√ß√£o de visualiza√ß√£o cient√≠fica (padr√£o IEEE)
    plt.style.use('seaborn-v0_8-whitegrid')
    sns.set_palette("husl")

@contextmanager
def experimental_session(self, 
                       phase: str, 
                       printer_firmware: str = "Unknown",
                       network_config: Dict[str, str] = None,
                       operator: str = "Pesquisador"):
    """
    Context manager para sess√µes experimentais rigorosas
    
    USO:
with logger.experimental_session("Fase_Descoberta") as session_id:
            # Seus experimentos aqui
            # Tudo ser√° registrado automaticamente
BENEF√çCIO: Garante que dados sejam salvos mesmo se houver erro
    """
    # Gera ID √∫nico baseado em hash de timestamp + fase
    session_id = hashlib.sha256(
        f"{datetime.now().isoformat()}_{phase}_{operator}".encode()
    ).hexdigest()[:16]
    
    conditions = ExperimentalConditions(
        session_id=session_id,
        start_time=datetime.now(),
        printer_firmware_version=printer_firmware,
        network_configuration=network_config or {},
        experimental_phase=phase,
        operator=operator
    )
    
    self.experimental_sessions[session_id] = conditions
    
    try:
        print(f"üî¨ Iniciando sess√£o experimental: {session_id}")
        print(f"   Fase: {phase}")
        print(f"   Operador: {operator}")
        yield session_id
    finally:
        # SEMPRE executa, mesmo com erro
        conditions.end_time = datetime.now()
        duration = conditions.end_time - conditions.start_time
        print(f"‚úÖ Sess√£o {session_id} conclu√≠da em {duration.total_seconds():.1f}s")
        
        # Salva dados imediatamente (n√£o espera final)
        self._save_session_data(session_id)

def log_command_execution(self,
                        session_id: str,
                        command_id: str,
                        command_payload: Dict[str, Any],
                        response_time_ms: Optional[float] = None,
                        response_payload: Optional[Dict[str, Any]] = None,
                        success_indicators: List[str] = None,
                        failure_indicators: List[str] = None,
                        retry_attempt: int = 0):
    """
    Registra execu√ß√£o individual de comando
    
    CHAMADA T√çPICA:

logger.log_command_execution(
            session_id=session_id,
            command_id="get_temperature",
            command_payload={"cmd": "get_temperature"},
            response_time_ms=12.5,
            response_payload={"nozzle": 210, "bed": 60},
            success_indicators=["temperature", "nozzle"],
            failure_indicators=[]
        )
IMPORTANTE: Chame isto para CADA comando executado
    """
    execution = CommandExecution(
        timestamp=datetime.now(),
        session_id=session_id,
        command_id=command_id,
        command_payload=command_payload,
        response_received=response_payload is not None,
        response_time_ms=response_time_ms,
        response_payload=response_payload,
        success_indicators=success_indicators or [],
        failure_indicators=failure_indicators or [],
        network_conditions=self._capture_network_conditions(),
        retry_attempt=retry_attempt
    )
    
    self.command_executions.append(execution)
    
    # Atualiza m√©tricas em tempo real
    if response_time_ms is not None:
        self._add_metric(f"response_time_{command_id}", response_time_ms)
    
    self._add_metric("success_rate_overall", 1.0 if execution.is_successful else 0.0)

def _capture_network_conditions(self) -> Dict[str, Any]:
    """
    Captura condi√ß√µes de rede
    
    NOTA: Vers√£o simplificada. Em produ√ß√£o, implementaria
    medi√ß√£o real de lat√™ncia via ping.
    """
    return {
        "timestamp": datetime.now().isoformat(),
        "latency_ms": 2.5,  # Placeholder - implementar ping real
        "packet_loss": 0.0,
        "bandwidth_mbps": 100.0
    }

def _add_metric(self, metric_name: str, value: float):
    """Adiciona m√©trica para an√°lise estat√≠stica"""
    if metric_name not in self.performance_metrics:
        self.performance_metrics[metric_name] = []
    self.performance_metrics[metric_name].append(value)

def _save_session_data(self, session_id: str):
    """
    Salva dados da sess√£o imediatamente
    
    PROP√ìSITO: Se houver crash, dados j√° est√£o salvos
    """
    session_data = {
        "conditions": asdict(self.experimental_sessions[session_id]),
        "executions": [
            asdict(exec) for exec in self.command_executions 
            if exec.session_id == session_id
        ]
    }
    
    session_file = self.data_directory / f"session_{session_id}.json"
    with open(session_file, 'w', encoding='utf-8') as f:
        json.dump(session_data, f, indent=2, default=str, ensure_ascii=False)

def generate_statistical_analysis(self) -> Dict[str, Any]:
    """
    Gera an√°lise estat√≠stica completa para publica√ß√£o A1
    
    OUTPUT: Dicion√°rio com:
    - Estat√≠sticas descritivas (m√©dia, mediana, etc.)
    - Testes de hip√≥teses
    - Intervalos de confian√ßa
    - Effect sizes
    
    IMPORTANTE: Chamado automaticamente ao final do experimento
    """
    analysis = {
        "experiment_metadata": {
            "name": self.experiment_name,
            "total_sessions": len(self.experimental_sessions),
            "total_executions": len(self.command_executions),
            "analysis_timestamp": datetime.now().isoformat()
        },
        "descriptive_statistics": {},
        "command_specific_analysis": {},
        "temporal_analysis": {}
    }
    
    # An√°lise descritiva para cada m√©trica
    for metric_name, values in self.performance_metrics.items():
        if len(values) >= 3:  # M√≠nimo para an√°lise estat√≠stica
            analysis["descriptive_statistics"][metric_name] = asdict(
                StatisticalSummary.from_data(metric_name, values)
            )
    
    # An√°lise por comando
    analysis["command_specific_analysis"] = self._analyze_by_command()
    
    return analysis

def _analyze_by_command(self) -> Dict[str, Any]:
    """
    An√°lise estat√≠stica espec√≠fica por comando
    
    RESULTADO: Para cada comando, calcula:
    - Taxa de sucesso
    - Tempo m√©dio de resposta
    - Estat√≠sticas completas
    """
    command_data = {}
    
    # Agrupa execu√ß√µes por comando
    for execution in self.command_executions:
        cmd_id = execution.command_id
        if cmd_id not in command_data:
            command_data[cmd_id] = {
                "response_times": [],
                "success_count": 0,
                "total_count": 0
            }
        
        cmd_data = command_data[cmd_id]
        cmd_data["total_count"] += 1
        
        if execution.response_time_ms is not None:
            cmd_data["response_times"].append(execution.response_time_ms)
        
        if execution.is_successful:
            cmd_data["success_count"] += 1
    
    # Calcula estat√≠sticas por comando
    analysis = {}
    for cmd_id, data in command_data.items():
        analysis[cmd_id] = {
            "success_rate": data["success_count"] / data["total_count"],
            "total_executions": data["total_count"],
            "response_time_stats": asdict(StatisticalSummary.from_data(
                f"response_time_{cmd_id}", 
                data["response_times"]
            )) if data["response_times"] else None
        }
    
    return analysis

def generate_publication_figures(self) -> List[str]:
    """
    Gera figuras de qualidade para publica√ß√£o A1
    
    OUTPUTS:
    - figure_response_time_distribution.png (300 DPI)
    - figure_success_rate_analysis.png (300 DPI)
    - figure_temporal_analysis.png (300 DPI)
    
    PADR√ÉO: IEEE - pronto para submiss√£o direta
    """
    figures_generated = []
    
    # Figura 1: Distribui√ß√£o de tempos de resposta
    fig1_path = self._create_response_time_plot()
    if fig1_path:
        figures_generated.append(fig1_path)
    
    # Figura 2: Taxa de sucesso por comando
    fig2_path = self._create_success_rate_plot()
    if fig2_path:
        figures_generated.append(fig2_path)
    
    return figures_generated

def _create_response_time_plot(self) -> Optional[str]:
    """Cria gr√°fico de tempos de resposta (violin plot)"""
    
    command_data = {}
    for exec in self.command_executions:
        if exec.response_time_ms is not None:
            if exec.command_id not in command_data:
                command_data[exec.command_id] = []
            command_data[exec.command_id].append(exec.response_time_ms)
    
    # Remove comandos com poucos dados
    command_data = {k: v for k, v in command_data.items() if len(v) >= 3}
    
    if not command_data:
        return None
    
    plt.figure(figsize=(12, 8))
    
    # Prepara dados para plot
    data_for_plot = []
    labels_for_plot = []
    
    for cmd_id, times in command_data.items():
        data_for_plot.extend(times)
        labels_for_plot.extend([cmd_id] * len(times))
    
    df_plot = pd.DataFrame({
        'Command': labels_for_plot,
        'Response_Time_ms': data_for_plot
    })
    
    # Violin plot com box plot interno
    sns.violinplot(data=df_plot, x='Command', y='Response_Time_ms', inner='box')
    plt.title('Distribui√ß√£o de Tempo de Resposta por Tipo de Comando', 
             fontsize=14, fontweight='bold')
    plt.xlabel('Tipo de Comando', fontsize=12)
    plt.ylabel('Tempo de Resposta (ms)', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    
    figure_path = self.data_directory / 'figure_response_time_distribution.png'
    plt.savefig(figure_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return str(figure_path)

def _create_success_rate_plot(self) -> Optional[str]:
    """Cria gr√°fico de taxa de sucesso"""
    
    command_stats = {}
    for exec in self.command_executions:
        if exec.command_id not in command_stats:
            command_stats[exec.command_id] = {'success': 0, 'total': 0}
        
        command_stats[exec.command_id]['total'] += 1
        if exec.is_successful:
            command_stats[exec.command_id]['success'] += 1
    
    if not command_stats:
        return None
    
    commands = []
    success_rates = []
    sample_sizes = []
    
    for cmd_id, stats_data in command_stats.items():
        if stats_data['total'] >= 3:
            commands.append(cmd_id)
            success_rate = stats_data['success'] / stats_data['total']
            success_rates.append(success_rate * 100)
            sample_sizes.append(stats_data['total'])
    
    if not commands:
        return None
    
    plt.figure(figsize=(10, 6))
    
    bars = plt.bar(commands, success_rates, alpha=0.7, color='steelblue')
    
    # Adiciona tamanho de amostra nos r√≥tulos
    for i, (bar, n) in enumerate(zip(bars, sample_sizes)):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'n={n}', ha='center', va='bottom', fontsize=10)
    
    plt.title('An√°lise de Taxa de Sucesso por Comando', 
             fontsize=14, fontweight='bold')
    plt.xlabel('Tipo de Comando', fontsize=12)
    plt.ylabel('Taxa de Sucesso (%)', fontsize=12)
    plt.ylim(0, 105)
    plt.xticks(rotation=45, ha='right')
    plt.axhline(y=90, color='red', linestyle='--', alpha=0.7, label='Threshold 90%')
    plt.legend()
    plt.tight_layout()
    
    figure_path = self.data_directory / 'figure_success_rate_analysis.png'
    plt.savefig(figure_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return str(figure_path)

def export_complete_dataset(self) -> str:
    """
    Exporta dataset completo para reposit√≥rio cient√≠fico
    
    OUTPUT: Arquivo JSON completo com:
    - Metadados do experimento
    - Todas as condi√ß√µes experimentais
    - Todas as execu√ß√µes registradas
    - An√°lise estat√≠stica
    - Dicion√°rio de dados para reprodutibilidade
    
    PROP√ìSITO: Compartilhar com comunidade cient√≠fica
    """
    dataset = {
        "metadata": {
            "experiment_name": self.experiment_name,
            "creation_date": datetime.now().isoformat(),
            "total_sessions": len(self.experimental_sessions),
            "total_executions": len(self.command_executions)
        },
        "experimental_conditions": [
            asdict(condition) for condition in self.experimental_sessions.values()
        ],
        "raw_executions": [
            asdict(exec) for exec in self.command_executions
        ],
        "statistical_summary": self.generate_statistical_analysis()
    }
    
    dataset_path = self.data_directory / f"{self.experiment_name}_complete_dataset.json"
    with open(dataset_path, 'w', encoding='utf-8') as f:
        json.dump(dataset, f, indent=2, default=str, ensure_ascii=False)
    
    # Tamb√©m exporta CSV para an√°lise em Excel/SPSS
    self._export_csv_datasets()
    
    return str(dataset_path)

def _export_csv_datasets(self):
    """Exporta datasets em CSV para an√°lise externa"""
    
    executions_data = []
    for exec in self.command_executions:
        executions_data.append({
            'session_id': exec.session_id,
            'timestamp': exec.timestamp.isoformat(),
            'command_id': exec.command_id,
            'response_time_ms': exec.response_time_ms,
            'success': exec.is_successful,
            'retry_attempt': exec.retry_attempt
        })
    
    df = pd.DataFrame(executions_data)
    df.to_csv(
        self.data_directory / f"{self.experiment_name}_executions.csv",
        index=False
    )
